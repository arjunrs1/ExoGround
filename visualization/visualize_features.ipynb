{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm\n",
    "import mplcursors\n",
    "\n",
    "# %matplotlib inline\n",
    "# %matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_features_from_dir(base_dir, distill=False):\n",
    "    # Initialize a dictionary to store features\n",
    "    if distill is False:\n",
    "        features = {\n",
    "            \"output_features\": [],\n",
    "            \"start_secs\": [],\n",
    "            \"exo_cams\": [],\n",
    "            \"video_ids\": []\n",
    "        }\n",
    "    else:\n",
    "        features = {\n",
    "            \"output_features\": [],\n",
    "            \"target_features\": [],\n",
    "            \"positive_feat_idxs\": [],\n",
    "            \"start_secs\": [],\n",
    "            \"exo_cams\": [],\n",
    "            \"video_ids\": []\n",
    "        }\n",
    "    # Check if the base directory exists\n",
    "    if not os.path.isdir(base_dir):\n",
    "        raise FileNotFoundError(f\"The directory {base_dir} does not exist.\")\n",
    "    # Mapping of filenames to dictionary keys\n",
    "    file_to_key = {\n",
    "        \"output_features.npy\": \"output_features\",\n",
    "        \"ego_seq.npy\": \"target_features\",\n",
    "        \"positive_feature_idxs_epoch.npy\": \"positive_feat_idxs\"\n",
    "    }\n",
    "    # Traverse the directory structure\n",
    "    i = 0\n",
    "    for root, dirs, files in os.walk(os.path.join(base_dir)):\n",
    "        parts = root.split(\"/\")\n",
    "        #if not parts[-3].startswith(\"georgiatech_covid_04\"):\n",
    "        #    continue\n",
    "        # if i >= 10:\n",
    "        #      break\n",
    "        # i += 1\n",
    "        if parts[-1].isdigit():\n",
    "            features[\"start_secs\"].append(parts[-1])\n",
    "            features[\"exo_cams\"].append(parts[-2])\n",
    "            features[\"video_ids\"].append(parts[-3])\n",
    "        for file in files:\n",
    "            if file in file_to_key and file_to_key[file] in features.keys():\n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    data = np.load(file_path)\n",
    "                    features[file_to_key[file]].append(data)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading {file_path}: {e}\")\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity_heatmap(input_features, target_features, positive_feat_idxs):\n",
    "    heatmaps = []\n",
    "    for inp, target, pos_idxs in zip(input_features, target_features, positive_feat_idxs):\n",
    "        # Extract positive view features\n",
    "        pos_features = np.array([target[pos_idx, i] for i, pos_idx in enumerate(pos_idxs)])\n",
    "        # Compute cosine similarity between input features and positive view features\n",
    "        similarity_matrix = cosine_similarity(inp, pos_features)\n",
    "        # Append the similarity matrix to the list of heatmaps\n",
    "        heatmaps.append(similarity_matrix)\n",
    "    return heatmaps\n",
    "    \n",
    "def plot_heatmap(similarity_matrix, title=\"Similarity Heatmap\"):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(similarity_matrix, cmap='hot', interpolation='nearest')\n",
    "    plt.colorbar()\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Positive View Features\")\n",
    "    plt.ylabel(\"Input Features\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_features(features):\n",
    "    # Flatten the list of feature arrays for normalization\n",
    "    flattened_features = np.vstack(features)\n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    normalized_features = scaler.fit_transform(flattened_features)\n",
    "    # Reshape back to original structure\n",
    "    split_indices = np.cumsum([len(f) for f in features[:-1]])\n",
    "    return np.split(normalized_features, split_indices)\n",
    "def extract_view_features(target_features, positive_feat_idxs):\n",
    "    all_view_features = []\n",
    "    positive_view_features = []\n",
    "    for target, pos_idxs in zip(target_features, positive_feat_idxs):\n",
    "        # Extract positive view features\n",
    "        pos_features = np.array([target[pos_idx, i] for i, pos_idx in enumerate(pos_idxs)])\n",
    "        positive_view_features.append(pos_features)\n",
    "        # Remove zero rows (views that are not available)\n",
    "        non_zero_views = target[np.any(target != 0, axis=(1, 2))]\n",
    "        # Flatten the first two dimensions to get all view features\n",
    "        all_views = non_zero_views.reshape(-1, target.shape[-1])\n",
    "        # Remove positive view features from all views\n",
    "        remaining_views = [view for view in all_views if not any(np.array_equal(view, pos) for pos in pos_features)]\n",
    "        all_view_features.append(np.array(remaining_views))\n",
    "    return all_view_features, positive_view_features\n",
    "\n",
    "def apply_tsne(output_features, all_view_features, positive_view_features):\n",
    "    tsne_results = []\n",
    "    for out, all_views, pos_views in tqdm(zip(output_features, all_view_features, positive_view_features), total=len(output_features)):\n",
    "        # Concatenate input, output, positive, and remaining view features\n",
    "        combined_features = np.vstack((out, pos_views, all_views))\n",
    "        # Apply t-SNE\n",
    "        tsne = TSNE(n_components=2, random_state=42)\n",
    "        tsne_result = tsne.fit_transform(combined_features)\n",
    "        tsne_results.append(tsne_result)\n",
    "    return tsne_results\n",
    "    \n",
    "\"\"\" def plot_tsne_OLD(tsne_result, input_len, no_curr_len, output_len, pos_len, video_id, exo_cam, start_sec, index, title=\"Video Features\"):\n",
    "    plt.figure(figsize=(16, 6))\n",
    "    # Plot input features\n",
    "    plt.scatter(tsne_result[:input_len, 0], tsne_result[:input_len, 1], label='w/o distill', alpha=0.5)\n",
    "    # Plot no_curr features\n",
    "    plt.scatter(tsne_result[input_len:input_len+no_curr_len, 0], tsne_result[input_len:input_len+no_curr_len, 1], label='w/o curriculum', alpha=0.5)\n",
    "\n",
    "    # Plot output features\n",
    "    plt.scatter(tsne_result[input_len+no_curr_len:input_len+no_curr_len+output_len, 0], tsne_result[input_len+no_curr_len:input_len+no_curr_len+output_len, 1], label='distill+curriculum', alpha=0.5)\n",
    "    # Plot positive view features\n",
    "    plt.scatter(tsne_result[input_len+no_curr_len+output_len:input_len+no_curr_len+output_len+pos_len, 0], tsne_result[input_len+no_curr_len+output_len:input_len+no_curr_len+output_len+pos_len, 1], label='best-view', alpha=0.5)\n",
    "    # Plot remaining view features\n",
    "    plt.scatter(tsne_result[input_len+no_curr_len+output_len+pos_len:, 0], tsne_result[input_len+no_curr_len+output_len+pos_len:, 1], label='other views', alpha=0.5)\n",
    "    plt.title(f\"Video: {video_id} Cam: {exo_cam} span: ({start_sec},{int(start_sec)+64}) s\")\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"{video_id}_{exo_cam}_{start_sec}_{int(start_sec)+64}.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def plot_tsne(tsne_result, output_len, pos_len, video_id, exo_cam, start_sec, index, title=\"Video Features\"):\n",
    "    plt.figure(figsize=(16, 6))\n",
    "\n",
    "    # Plot output features\n",
    "    plt.scatter(tsne_result[:output_len, 0], tsne_result[:output_len, 1], label='distill+curriculum', alpha=0.5)\n",
    "    # Plot positive view features\n",
    "    plt.scatter(tsne_result[output_len:output_len+pos_len, 0], tsne_result[output_len:output_len+pos_len, 1], label='best-view', alpha=0.5)\n",
    "    # Plot remaining view features\n",
    "    plt.scatter(tsne_result[output_len+pos_len:, 0], tsne_result[output_len+pos_len:, 1], label='other views', alpha=0.5)\n",
    "    plt.title(f\"Video: {video_id} Cam: {exo_cam} span: ({start_sec},{int(start_sec)+64}) s\")\n",
    "    plt.legend()\n",
    "    #plt.savefig(f\"{video_id}_{exo_cam}_{start_sec}_{int(start_sec)+64}.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show() \"\"\"\n",
    "\n",
    "def plot_tsne(tsne_result, output_len, pos_len, video_id, exo_cam, start_sec, index, title=\"Video Features\"):\n",
    "    # Generate labels for each group\n",
    "    output_labels = [i % 64 for i in range(output_len)]\n",
    "    pos_labels = [i % 64 for i in range(pos_len)]\n",
    "    other_labels = [i % 64 for i in range(len(tsne_result) - output_len - pos_len)]\n",
    "\n",
    "    # Plot without labels\n",
    "    plt.figure(figsize=(16, 6))\n",
    "    plt.scatter(tsne_result[:output_len, 0], tsne_result[:output_len, 1], label='distill+curriculum', color='green', alpha=0.5)\n",
    "    plt.scatter(tsne_result[output_len:output_len+pos_len, 0], tsne_result[output_len:output_len+pos_len, 1], label='best-view', color='blue', alpha=0.5)\n",
    "    plt.scatter(tsne_result[output_len+pos_len:, 0], tsne_result[output_len+pos_len:, 1], label='other views', color='red', alpha=0.5)\n",
    "    plt.title(f\"Video: {video_id} Cam: {exo_cam} span: ({start_sec},{int(start_sec)+64}) s - Without Labels\")\n",
    "    plt.savefig(f\"{video_id}_{exo_cam}_{start_sec}_{int(start_sec)+64}.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot with labels\n",
    "    plt.figure(figsize=(16, 6))\n",
    "    scatter_output = plt.scatter(tsne_result[:output_len, 0], tsne_result[:output_len, 1], label='distill+curriculum', color='green', alpha=0.5)\n",
    "    scatter_pos = plt.scatter(tsne_result[output_len:output_len+pos_len, 0], tsne_result[output_len:output_len+pos_len, 1], label='best-view', color='blue', alpha=0.5)\n",
    "    scatter_other = plt.scatter(tsne_result[output_len+pos_len:, 0], tsne_result[output_len+pos_len:, 1], label='other views', color='red', alpha=0.5)\n",
    "    plt.title(f\"Video: {video_id} Cam: {exo_cam} span: ({start_sec},{int(start_sec)+64}) s - With Labels\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Annotate each point with its label\n",
    "    for i, label in enumerate(output_labels):\n",
    "        plt.annotate(label, (tsne_result[i, 0], tsne_result[i, 1]), fontsize=8, alpha=0.7)\n",
    "    for i, label in enumerate(pos_labels):\n",
    "        plt.annotate(label, (tsne_result[output_len + i, 0], tsne_result[output_len + i, 1]), fontsize=8, alpha=0.7)\n",
    "    for i, label in enumerate(other_labels):\n",
    "        plt.annotate(label, (tsne_result[output_len + pos_len + i, 0], tsne_result[output_len + pos_len + i, 1]), fontsize=8, alpha=0.7)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_dir = \"/private/home/arjunrs1/exo_narration_grounding/ExoGround/train/log/\"\n",
    "no_distill_model_name = \"/private/home/arjunrs1/exo_narration_grounding/ExoGround/train/log/joint_nodist_b16_2024_10_29_06_36_joint_iou_l1_egoexo4d_len64_e6d6_bs16_lr0.0001_view=all_distill=False_pair_ds=False_pair_ds_mode=all_multi_ego=False_narr_rand=False\"\n",
    "no_curr_model_name = \"/private/home/arjunrs1/exo_narration_grounding/ExoGround/train/log/wocurr_2024_11_09_00_45_joint_iou_l1_egoexo4d_len64_e6d6_bs16_lr0.0001_view=all_distill=True_pair_ds=False_pair_ds_mode=all_multi_ego=False_narr_rand=False\"\n",
    "distill_model_name = \"/private/home/arjunrs1/exo_narration_grounding/ExoGround/train/log/PX_50_200_2024_11_08_13_21_joint_iou_l1_egoexo4d_len64_e6d6_bs16_lr0.0001_view=all_distill=True_pair_ds=False_pair_ds_mode=all_multi_ego=False_narr_rand=False\"\n",
    "\n",
    "no_distill_model_dir = os.path.join(runs_dir, no_distill_model_name, \"log\", \"saved_features\")\n",
    "no_curr_model_dir = os.path.join(runs_dir, no_curr_model_name, \"log\", \"saved_features\")\n",
    "distill_model_dir = os.path.join(runs_dir, distill_model_name, \"log\", \"saved_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_no_distill = load_features_from_dir(no_distill_model_dir)\n",
    "outputs_no_curr = load_features_from_dir(no_curr_model_dir) #we don't set distill true here even though it is a distill mode, because we just want the output features\n",
    "outputs_distill = load_features_from_dir(distill_model_dir, distill=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize heatmap:\n",
    "#heatmaps = compute_similarity_heatmap(outputs['input_features'], outputs['target_features'], outputs['positive_feat_idxs'])\n",
    "#plot_heatmap(heatmaps[0], title=\"Input/Target Similarity Heatmap for First Video\")\n",
    "#heatmaps = compute_similarity_heatmap(outputs['output_features'], outputs['target_features'], outputs['positive_feat_idxs'])\n",
    "#plot_heatmap(heatmaps[0], title=\"Output/Target Similarity Heatmap for First Video\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing no distill features...\n",
      "Normalizing no distill features...\n",
      "Normalizing features...\n",
      "Extracting all-view and positive features...\n"
     ]
    }
   ],
   "source": [
    "#t-SNE:\n",
    "# Normalize input and output features\n",
    "print(\"Normalizing no distill features...\")\n",
    "normalized_input_features = normalize_features(outputs_no_distill['output_features'])\n",
    "print(\"Normalizing no distill features...\")\n",
    "normalized_no_curr_features = normalize_features(outputs_no_curr['output_features'])\n",
    "print(\"Normalizing features...\")\n",
    "normalized_output_features = normalize_features(outputs_distill['output_features'])\n",
    "\n",
    "print(\"Extracting all-view and positive features...\")\n",
    "all_view_features, positive_view_features = extract_view_features(outputs_distill['target_features'], outputs_distill['positive_feat_idxs'])\n",
    "print(\"Normalizing all_view_features features...\")\n",
    "normalized_all_view_features = normalize_features(all_view_features)\n",
    "print(\"Normalizing positive_view features...\")\n",
    "normalized_positive_view_features = normalize_features(positive_view_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply t-SNE\n",
    "tsne_results = apply_tsne(normalized_output_features,\n",
    "                            normalized_all_view_features,\n",
    "                            normalized_positive_view_features)\n",
    "\n",
    "for i, tsne_result in enumerate(tsne_results):\n",
    "        plot_tsne(tsne_result, \n",
    "                  len(normalized_output_features[i]), \n",
    "                  len(normalized_positive_view_features[i]),\n",
    "                  outputs_distill['video_ids'][i],\n",
    "                  outputs_distill['exo_cams'][i],\n",
    "                  outputs_distill['start_secs'][i],\n",
    "                  i, \n",
    "                  title=\"t-SNE Visualization\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sounding_narrations",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
